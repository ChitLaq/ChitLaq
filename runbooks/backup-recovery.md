# ChitLaq M1 MVP - Backup & Recovery Runbook

> **Generated by PROMPT 1.7** - Infrastructure Documentation & Knowledge Transfer  
> **Senior Technical Writer & Infrastructure Architect** - 15+ years system documentation and knowledge transfer experience

## Executive Summary

This backup and recovery runbook provides comprehensive procedures for data backup, restoration, and disaster recovery in the ChitLaq M1 MVP infrastructure. It ensures data protection, business continuity, and rapid recovery from various failure scenarios.

## Table of Contents
- [Backup Strategy](#backup-strategy)
- [Backup Procedures](#backup-procedures)
- [Recovery Procedures](#recovery-procedures)
- [Disaster Recovery](#disaster-recovery)
- [Testing and Validation](#testing-and-validation)
- [Monitoring and Alerting](#monitoring-and-alerting)
- [Documentation and Maintenance](#documentation-and-maintenance)

## Backup Strategy

### Backup Types

#### Full Backup
- **Frequency**: Daily at 2:00 AM UTC
- **Retention**: 30 days
- **Location**: `/opt/backups/chitlaq/full/`
- **Size**: ~500MB (estimated)

#### Incremental Backup
- **Frequency**: Every 6 hours
- **Retention**: 7 days
- **Location**: `/opt/backups/chitlaq/incremental/`
- **Size**: ~50MB (estimated)

#### Configuration Backup
- **Frequency**: Daily at 3:00 AM UTC
- **Retention**: 90 days
- **Location**: `/opt/backups/chitlaq/config/`
- **Size**: ~10MB (estimated)

### Backup Locations

#### Local Storage
- **Primary**: `/opt/backups/chitlaq/`
- **Secondary**: `/var/backups/chitlaq/`
- **Tertiary**: `/tmp/backups/chitlaq/`

#### Remote Storage
- **Cloud**: AWS S3 (encrypted)
- **Secondary**: Google Cloud Storage (encrypted)
- **Tertiary**: Local NAS (encrypted)

## Backup Procedures

### Database Backup

#### Full Database Backup
```bash
#!/bin/bash
# Full database backup script

BACKUP_DIR="/opt/backups/chitlaq/full"
DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_FILE="chitlaq_full_${DATE}.sql"
ENCRYPTED_FILE="${BACKUP_FILE}.enc"

# Create backup directory
mkdir -p $BACKUP_DIR

# Perform full backup
docker compose exec postgres pg_dump -U postgres -h localhost -d chitlaq > $BACKUP_DIR/$BACKUP_FILE

# Encrypt backup
openssl enc -aes-256-gcm -pbkdf2 -in $BACKUP_DIR/$BACKUP_FILE -out $BACKUP_DIR/$ENCRYPTED_FILE -pass pass:$BACKUP_PASSWORD

# Remove unencrypted file
rm $BACKUP_DIR/$BACKUP_FILE

# Compress backup
gzip $BACKUP_DIR/$ENCRYPTED_FILE

# Upload to remote storage
aws s3 cp $BACKUP_DIR/${ENCRYPTED_FILE}.gz s3://chitlaq-backups/database/full/

# Clean up old backups (keep 30 days)
find $BACKUP_DIR -name "*.gz" -mtime +30 -delete

echo "Full backup completed: ${ENCRYPTED_FILE}.gz"
```

#### Incremental Database Backup
```bash
#!/bin/bash
# Incremental database backup script

BACKUP_DIR="/opt/backups/chitlaq/incremental"
DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_FILE="chitlaq_incremental_${DATE}.sql"
ENCRYPTED_FILE="${BACKUP_FILE}.enc"

# Create backup directory
mkdir -p $BACKUP_DIR

# Get last backup timestamp
LAST_BACKUP=$(find $BACKUP_DIR -name "*.gz" -type f -printf '%T@ %p\n' | sort -n | tail -1 | cut -d' ' -f2)

# Perform incremental backup
docker compose exec postgres pg_dump -U postgres -h localhost -d chitlaq --since="$LAST_BACKUP" > $BACKUP_DIR/$BACKUP_FILE

# Encrypt backup
openssl enc -aes-256-gcm -pbkdf2 -in $BACKUP_DIR/$BACKUP_FILE -out $BACKUP_DIR/$ENCRYPTED_FILE -pass pass:$BACKUP_PASSWORD

# Remove unencrypted file
rm $BACKUP_DIR/$BACKUP_FILE

# Compress backup
gzip $BACKUP_DIR/$ENCRYPTED_FILE

# Upload to remote storage
aws s3 cp $BACKUP_DIR/${ENCRYPTED_FILE}.gz s3://chitlaq-backups/database/incremental/

# Clean up old backups (keep 7 days)
find $BACKUP_DIR -name "*.gz" -mtime +7 -delete

echo "Incremental backup completed: ${ENCRYPTED_FILE}.gz"
```

### Configuration Backup

#### System Configuration Backup
```bash
#!/bin/bash
# System configuration backup script

BACKUP_DIR="/opt/backups/chitlaq/config"
DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_FILE="chitlaq_config_${DATE}.tar.gz"
ENCRYPTED_FILE="${BACKUP_FILE}.enc"

# Create backup directory
mkdir -p $BACKUP_DIR

# Create configuration backup
tar -czf $BACKUP_DIR/$BACKUP_FILE \
  /etc/nginx/ \
  /etc/docker/ \
  /etc/systemd/ \
  /opt/chitlaq/docker-compose.yml \
  /opt/chitlaq/.env \
  /opt/chitlaq/nginx/ \
  /opt/chitlaq/monitoring/ \
  /opt/chitlaq/scripts/

# Encrypt backup
openssl enc -aes-256-gcm -pbkdf2 -in $BACKUP_DIR/$BACKUP_FILE -out $BACKUP_DIR/$ENCRYPTED_FILE -pass pass:$BACKUP_PASSWORD

# Remove unencrypted file
rm $BACKUP_DIR/$BACKUP_FILE

# Upload to remote storage
aws s3 cp $BACKUP_DIR/$ENCRYPTED_FILE s3://chitlaq-backups/config/

# Clean up old backups (keep 90 days)
find $BACKUP_DIR -name "*.enc" -mtime +90 -delete

echo "Configuration backup completed: $ENCRYPTED_FILE"
```

### Application Data Backup

#### User Uploads Backup
```bash
#!/bin/bash
# User uploads backup script

BACKUP_DIR="/opt/backups/chitlaq/uploads"
DATE=$(date +%Y%m%d_%H%M%S)
BACKUP_FILE="chitlaq_uploads_${DATE}.tar.gz"
ENCRYPTED_FILE="${BACKUP_FILE}.enc"

# Create backup directory
mkdir -p $BACKUP_DIR

# Create uploads backup
tar -czf $BACKUP_DIR/$BACKUP_FILE \
  /opt/chitlaq/storage/uploads/ \
  /opt/chitlaq/storage/avatars/ \
  /opt/chitlaq/storage/thumbnails/

# Encrypt backup
openssl enc -aes-256-gcm -pbkdf2 -in $BACKUP_DIR/$BACKUP_FILE -out $BACKUP_DIR/$ENCRYPTED_FILE -pass pass:$BACKUP_PASSWORD

# Remove unencrypted file
rm $BACKUP_DIR/$BACKUP_FILE

# Upload to remote storage
aws s3 cp $BACKUP_DIR/$ENCRYPTED_FILE s3://chitlaq-backups/uploads/

# Clean up old backups (keep 30 days)
find $BACKUP_DIR -name "*.enc" -mtime +30 -delete

echo "Uploads backup completed: $ENCRYPTED_FILE"
```

## Recovery Procedures

### Database Recovery

#### Full Database Recovery
```bash
#!/bin/bash
# Full database recovery script

BACKUP_FILE=$1
BACKUP_DIR="/opt/backups/chitlaq/full"
TEMP_DIR="/tmp/recovery"

if [ -z "$BACKUP_FILE" ]; then
    echo "Usage: $0 <backup_file>"
    echo "Available backups:"
    ls -la $BACKUP_DIR/*.gz
    exit 1
fi

# Create temporary directory
mkdir -p $TEMP_DIR

# Download backup if from remote
if [[ $BACKUP_FILE == s3://* ]]; then
    aws s3 cp $BACKUP_FILE $TEMP_DIR/
    BACKUP_FILE=$TEMP_DIR/$(basename $BACKUP_FILE)
fi

# Decrypt backup
openssl enc -aes-256-gcm -pbkdf2 -d -in $BACKUP_FILE -out $TEMP_DIR/backup.sql -pass pass:$BACKUP_PASSWORD

# Stop applications
docker compose stop

# Drop and recreate database
docker compose exec postgres psql -U postgres -c "DROP DATABASE IF EXISTS chitlaq;"
docker compose exec postgres psql -U postgres -c "CREATE DATABASE chitlaq;"

# Restore database
docker compose exec postgres psql -U postgres -d chitlaq < $TEMP_DIR/backup.sql

# Start applications
docker compose start

# Verify recovery
docker compose exec postgres psql -U postgres -d chitlaq -c "SELECT count(*) FROM users;"

# Clean up
rm -rf $TEMP_DIR

echo "Database recovery completed successfully"
```

#### Point-in-Time Recovery
```bash
#!/bin/bash
# Point-in-time recovery script

TARGET_TIME=$1
BACKUP_DIR="/opt/backups/chitlaq"

if [ -z "$TARGET_TIME" ]; then
    echo "Usage: $0 <target_time> (YYYY-MM-DD HH:MM:SS)"
    exit 1
fi

# Find latest full backup before target time
FULL_BACKUP=$(find $BACKUP_DIR/full -name "*.gz" -newermt "$TARGET_TIME" | sort | tail -1)

# Find incremental backups after full backup
INCREMENTAL_BACKUPS=$(find $BACKUP_DIR/incremental -name "*.gz" -newer "$FULL_BACKUP" -not -newermt "$TARGET_TIME" | sort)

# Restore full backup
./scripts/restore-full-backup.sh $FULL_BACKUP

# Apply incremental backups
for backup in $INCREMENTAL_BACKUPS; do
    echo "Applying incremental backup: $backup"
    ./scripts/restore-incremental-backup.sh $backup
done

echo "Point-in-time recovery completed to: $TARGET_TIME"
```

### Configuration Recovery

#### System Configuration Recovery
```bash
#!/bin/bash
# System configuration recovery script

BACKUP_FILE=$1
BACKUP_DIR="/opt/backups/chitlaq/config"
TEMP_DIR="/tmp/config-recovery"

if [ -z "$BACKUP_FILE" ]; then
    echo "Usage: $0 <backup_file>"
    echo "Available backups:"
    ls -la $BACKUP_DIR/*.enc
    exit 1
fi

# Create temporary directory
mkdir -p $TEMP_DIR

# Download backup if from remote
if [[ $BACKUP_FILE == s3://* ]]; then
    aws s3 cp $BACKUP_FILE $TEMP_DIR/
    BACKUP_FILE=$TEMP_DIR/$(basename $BACKUP_FILE)
fi

# Decrypt backup
openssl enc -aes-256-gcm -pbkdf2 -d -in $BACKUP_FILE -out $TEMP_DIR/config.tar.gz -pass pass:$BACKUP_PASSWORD

# Extract configuration
tar -xzf $TEMP_DIR/config.tar.gz -C /

# Restart services
systemctl restart nginx
systemctl restart docker
docker compose restart

# Verify recovery
./scripts/health-check.sh

# Clean up
rm -rf $TEMP_DIR

echo "Configuration recovery completed successfully"
```

### Application Data Recovery

#### User Uploads Recovery
```bash
#!/bin/bash
# User uploads recovery script

BACKUP_FILE=$1
BACKUP_DIR="/opt/backups/chitlaq/uploads"
TEMP_DIR="/tmp/uploads-recovery"

if [ -z "$BACKUP_FILE" ]; then
    echo "Usage: $0 <backup_file>"
    echo "Available backups:"
    ls -la $BACKUP_DIR/*.enc
    exit 1
fi

# Create temporary directory
mkdir -p $TEMP_DIR

# Download backup if from remote
if [[ $BACKUP_FILE == s3://* ]]; then
    aws s3 cp $BACKUP_FILE $TEMP_DIR/
    BACKUP_FILE=$TEMP_DIR/$(basename $BACKUP_FILE)
fi

# Decrypt backup
openssl enc -aes-256-gcm -pbkdf2 -d -in $BACKUP_FILE -out $TEMP_DIR/uploads.tar.gz -pass pass:$BACKUP_PASSWORD

# Extract uploads
tar -xzf $TEMP_DIR/uploads.tar.gz -C /

# Set proper permissions
chown -R www-data:www-data /opt/chitlaq/storage/
chmod -R 755 /opt/chitlaq/storage/

# Clean up
rm -rf $TEMP_DIR

echo "Uploads recovery completed successfully"
```

## Disaster Recovery

### Complete System Recovery

#### VPS Recovery
```bash
#!/bin/bash
# Complete VPS recovery script

# 1. Provision new VPS
# 2. Install base system
# 3. Install Docker and dependencies
# 4. Restore configuration
# 5. Restore database
# 6. Restore application data
# 7. Start services
# 8. Verify recovery

echo "Starting complete system recovery..."

# Install base system
apt update && apt upgrade -y
apt install -y docker.io docker-compose nginx certbot

# Install ChitLaq
git clone https://github.com/chitlaq/chitlaq.git /opt/chitlaq
cd /opt/chitlaq

# Restore configuration
./scripts/restore-config.sh s3://chitlaq-backups/config/latest.enc

# Restore database
./scripts/restore-database.sh s3://chitlaq-backups/database/full/latest.gz

# Restore application data
./scripts/restore-uploads.sh s3://chitlaq-backups/uploads/latest.enc

# Start services
docker compose up -d

# Verify recovery
./scripts/health-check.sh

echo "Complete system recovery completed successfully"
```

### Partial System Recovery

#### Service Recovery
```bash
#!/bin/bash
# Service recovery script

SERVICE=$1

case $SERVICE in
    "database")
        echo "Recovering database service..."
        docker compose restart postgres
        ./scripts/verify-database.sh
        ;;
    "api")
        echo "Recovering API service..."
        docker compose restart api-gateway
        ./scripts/verify-api.sh
        ;;
    "websocket")
        echo "Recovering WebSocket service..."
        docker compose restart websocket
        ./scripts/verify-websocket.sh
        ;;
    "monitoring")
        echo "Recovering monitoring services..."
        docker compose restart prometheus grafana
        ./scripts/verify-monitoring.sh
        ;;
    *)
        echo "Unknown service: $SERVICE"
        echo "Available services: database, api, websocket, monitoring"
        exit 1
        ;;
esac

echo "Service recovery completed: $SERVICE"
```

## Testing and Validation

### Backup Testing

#### Backup Integrity Test
```bash
#!/bin/bash
# Backup integrity test script

BACKUP_FILE=$1
TEMP_DIR="/tmp/backup-test"

if [ -z "$BACKUP_FILE" ]; then
    echo "Usage: $0 <backup_file>"
    exit 1
fi

# Create temporary directory
mkdir -p $TEMP_DIR

# Test backup integrity
if [[ $BACKUP_FILE == *.gz ]]; then
    gzip -t $BACKUP_FILE
    echo "Backup file integrity: OK"
else
    echo "Backup file integrity: Unknown format"
fi

# Test decryption
if [[ $BACKUP_FILE == *.enc ]]; then
    openssl enc -aes-256-gcm -pbkdf2 -d -in $BACKUP_FILE -out $TEMP_DIR/test.sql -pass pass:$BACKUP_PASSWORD
    if [ $? -eq 0 ]; then
        echo "Backup decryption: OK"
        rm $TEMP_DIR/test.sql
    else
        echo "Backup decryption: FAILED"
        exit 1
    fi
fi

# Clean up
rm -rf $TEMP_DIR

echo "Backup integrity test completed successfully"
```

#### Recovery Testing
```bash
#!/bin/bash
# Recovery testing script

BACKUP_FILE=$1
TEST_DB="chitlaq_test"

if [ -z "$BACKUP_FILE" ]; then
    echo "Usage: $0 <backup_file>"
    exit 1
fi

# Create test database
docker compose exec postgres psql -U postgres -c "DROP DATABASE IF EXISTS $TEST_DB;"
docker compose exec postgres psql -U postgres -c "CREATE DATABASE $TEST_DB;"

# Restore to test database
./scripts/restore-to-test-db.sh $BACKUP_FILE $TEST_DB

# Verify test database
docker compose exec postgres psql -U postgres -d $TEST_DB -c "SELECT count(*) FROM users;"
docker compose exec postgres psql -U postgres -d $TEST_DB -c "SELECT count(*) FROM posts;"
docker compose exec postgres psql -U postgres -d $TEST_DB -c "SELECT count(*) FROM messages;"

# Clean up test database
docker compose exec postgres psql -U postgres -c "DROP DATABASE $TEST_DB;"

echo "Recovery testing completed successfully"
```

### Disaster Recovery Testing

#### Full DR Test
```bash
#!/bin/bash
# Full disaster recovery test script

echo "Starting full disaster recovery test..."

# 1. Create test environment
./scripts/create-test-environment.sh

# 2. Simulate disaster
./scripts/simulate-disaster.sh

# 3. Test recovery procedures
./scripts/test-recovery-procedures.sh

# 4. Verify system functionality
./scripts/verify-system-functionality.sh

# 5. Clean up test environment
./scripts/cleanup-test-environment.sh

echo "Full disaster recovery test completed successfully"
```

## Monitoring and Alerting

### Backup Monitoring

#### Backup Status Monitoring
```bash
#!/bin/bash
# Backup status monitoring script

BACKUP_DIR="/opt/backups/chitlaq"
ALERT_EMAIL="alerts@chitlaq.com"

# Check last full backup
LAST_FULL_BACKUP=$(find $BACKUP_DIR/full -name "*.gz" -type f -printf '%T@ %p\n' | sort -n | tail -1 | cut -d' ' -f2)
LAST_FULL_TIME=$(stat -c %Y $LAST_FULL_BACKUP)
CURRENT_TIME=$(date +%s)
FULL_BACKUP_AGE=$((CURRENT_TIME - LAST_FULL_TIME))

# Check last incremental backup
LAST_INC_BACKUP=$(find $BACKUP_DIR/incremental -name "*.gz" -type f -printf '%T@ %p\n' | sort -n | tail -1 | cut -d' ' -f2)
LAST_INC_TIME=$(stat -c %Y $LAST_INC_BACKUP)
INC_BACKUP_AGE=$((CURRENT_TIME - LAST_INC_TIME))

# Alert if backups are too old
if [ $FULL_BACKUP_AGE -gt 86400 ]; then
    echo "ALERT: Full backup is older than 24 hours" | mail -s "Backup Alert" $ALERT_EMAIL
fi

if [ $INC_BACKUP_AGE -gt 21600 ]; then
    echo "ALERT: Incremental backup is older than 6 hours" | mail -s "Backup Alert" $ALERT_EMAIL
fi

echo "Backup monitoring completed"
```

#### Backup Size Monitoring
```bash
#!/bin/bash
# Backup size monitoring script

BACKUP_DIR="/opt/backups/chitlaq"
ALERT_EMAIL="alerts@chitlaq.com"

# Check backup directory size
BACKUP_SIZE=$(du -sh $BACKUP_DIR | cut -f1)
BACKUP_SIZE_BYTES=$(du -sb $BACKUP_DIR | cut -f1)

# Alert if backup size is too large
if [ $BACKUP_SIZE_BYTES -gt 10737418240 ]; then  # 10GB
    echo "ALERT: Backup directory size is larger than 10GB: $BACKUP_SIZE" | mail -s "Backup Size Alert" $ALERT_EMAIL
fi

echo "Backup size monitoring completed: $BACKUP_SIZE"
```

### Recovery Monitoring

#### Recovery Time Monitoring
```bash
#!/bin/bash
# Recovery time monitoring script

RECOVERY_LOG="/var/log/recovery.log"
ALERT_EMAIL="alerts@chitlaq.com"

# Check last recovery time
if [ -f $RECOVERY_LOG ]; then
    LAST_RECOVERY=$(tail -1 $RECOVERY_LOG | cut -d' ' -f1)
    RECOVERY_TIME=$(tail -1 $RECOVERY_LOG | cut -d' ' -f2)
    
    # Alert if recovery time is too long
    if [ $RECOVERY_TIME -gt 3600 ]; then  # 1 hour
        echo "ALERT: Last recovery took longer than 1 hour: $RECOVERY_TIME seconds" | mail -s "Recovery Time Alert" $ALERT_EMAIL
    fi
fi

echo "Recovery time monitoring completed"
```

## Documentation and Maintenance

### Backup Documentation

#### Backup Log
```bash
#!/bin/bash
# Backup log script

BACKUP_LOG="/var/log/backup.log"
DATE=$(date '+%Y-%m-%d %H:%M:%S')

# Log backup information
echo "$DATE - Backup started" >> $BACKUP_LOG
echo "$DATE - Backup type: $1" >> $BACKUP_LOG
echo "$DATE - Backup file: $2" >> $BACKUP_LOG
echo "$DATE - Backup size: $3" >> $BACKUP_LOG
echo "$DATE - Backup completed" >> $BACKUP_LOG
```

#### Recovery Log
```bash
#!/bin/bash
# Recovery log script

RECOVERY_LOG="/var/log/recovery.log"
DATE=$(date '+%Y-%m-%d %H:%M:%S')

# Log recovery information
echo "$DATE - Recovery started" >> $RECOVERY_LOG
echo "$DATE - Recovery type: $1" >> $RECOVERY_LOG
echo "$DATE - Recovery file: $2" >> $RECOVERY_LOG
echo "$DATE - Recovery completed" >> $RECOVERY_LOG
```

### Maintenance Procedures

#### Backup Cleanup
```bash
#!/bin/bash
# Backup cleanup script

BACKUP_DIR="/opt/backups/chitlaq"

# Clean up old full backups (keep 30 days)
find $BACKUP_DIR/full -name "*.gz" -mtime +30 -delete

# Clean up old incremental backups (keep 7 days)
find $BACKUP_DIR/incremental -name "*.gz" -mtime +7 -delete

# Clean up old configuration backups (keep 90 days)
find $BACKUP_DIR/config -name "*.enc" -mtime +90 -delete

# Clean up old uploads backups (keep 30 days)
find $BACKUP_DIR/uploads -name "*.enc" -mtime +30 -delete

echo "Backup cleanup completed"
```

#### Backup Verification
```bash
#!/bin/bash
# Backup verification script

BACKUP_DIR="/opt/backups/chitlaq"

# Verify backup integrity
for backup in $(find $BACKUP_DIR -name "*.gz" -type f); do
    if gzip -t $backup; then
        echo "OK: $backup"
    else
        echo "FAILED: $backup"
    fi
done

# Verify backup encryption
for backup in $(find $BACKUP_DIR -name "*.enc" -type f); do
    if openssl enc -aes-256-gcm -pbkdf2 -d -in $backup -out /dev/null -pass pass:$BACKUP_PASSWORD; then
        echo "OK: $backup"
    else
        echo "FAILED: $backup"
    fi
done

echo "Backup verification completed"
```

## Conclusion

This backup and recovery runbook provides comprehensive procedures for data protection and disaster recovery in the ChitLaq M1 MVP infrastructure. Following these procedures ensures data safety, business continuity, and rapid recovery from various failure scenarios.

Key backup and recovery principles:
1. **Regularity**: Consistent backup schedules
2. **Verification**: Regular backup testing and validation
3. **Security**: Encrypted backups and secure storage
4. **Documentation**: Thorough logging and documentation
5. **Testing**: Regular disaster recovery testing

Regular review and updates of this runbook ensure it remains current and effective for backup and recovery operations.

---

**Document Version**: 1.0  
**Last Updated**: 2024  
**Next Review**: Monthly  
**Maintained by**: ChitLaq Operations Team
